{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw like a man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No|Title of Article | Interesting?\n",
    "---|---|---\n",
    "1|oracle open sources java machine learning library | yes\n",
    "2|the reason trump not trying save economy | no\n",
    "3|it fed day time for the economy to get tuneup | no\n",
    "4|auto ml bridging skill gaps with machine learning | yes\n",
    "5|donald trump chance to peel off hispanic voters | no\n",
    "6|definining ai machine learning deep learning martech | yes\n",
    "7|ai macine learning tool can help separate covid related claim | yes\n",
    "8|dbs taking machine learning for spin | yes\n",
    "9|deepmind introduce machine learning model improve google maps | yes\n",
    "10|we must use covid crisis rehape society economy | no\n",
    "\n",
    "Tentukan kelas interestingness (yes/ no) dari dua judul artikel berikut dengan Naive Bayes :\n",
    "\n",
    "1. system target ai adoption challenge machine learning builder\n",
    "2. trump destroying economy though\n",
    "\n",
    "Lakukan estimasi dengan Maximum a Priory (MAP) dengan asumsi bahwa semua kata (baik\n",
    "yang muncul dalam vocabulary atau tidak) memiliki kemunculan ‘halucinated’ sekali sebagai\n",
    "prior knowledge nya. Tunjukkan cara menghitungnya dimulai dengan formula yang dipakai,\n",
    "misal P(yes | kalimat) = ……, lalu isikan nilai probability sesuai dengan urutan dalam formula\n",
    "dalam bentuk pembilang/penyebut. Pecahan desimal hanya ditulis untuk hasil akhir.\n",
    "Hint: hitung nilai probability yang hanya diperlukan untuk dapat mengklasifikasn kedua kalimat\n",
    "yang ditanyakan kelasnya di atas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Title of Article</th>\n",
       "      <th>Interesting?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>oracle open sources java machine learning library</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the reason trump not trying save economy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>it fed day time for the economy to get tuneup</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>auto ml bridging skill gaps with machine learning</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>donald trump chance to peel off hispanic voters</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>definining ai machine learning deep learning m...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ai machine learning tool can help separate cov...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>dbs taking machine learning for spin</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>deepmind introduce machine learning model impr...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>we must use covid crisis rehape society economy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                   Title of Article Interesting?\n",
       "0   1  oracle open sources java machine learning library          yes\n",
       "1   2           the reason trump not trying save economy           no\n",
       "2   3      it fed day time for the economy to get tuneup           no\n",
       "3   4  auto ml bridging skill gaps with machine learning          yes\n",
       "4   5    donald trump chance to peel off hispanic voters           no\n",
       "5   6  definining ai machine learning deep learning m...          yes\n",
       "6   7  ai machine learning tool can help separate cov...          yes\n",
       "7   8               dbs taking machine learning for spin          yes\n",
       "8   9  deepmind introduce machine learning model impr...          yes\n",
       "9  10    we must use covid crisis rehape society economy           no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = {'yes':{}, 'no':{}}\n",
    "prior_yes = 6/10\n",
    "prior_no = 4/10\n",
    "n_text = defaultdict(int)\n",
    "n_unique_text = defaultdict(int)\n",
    "total_words = set()\n",
    "for i, row in data.iterrows():\n",
    "    text = row['Title of Article']\n",
    "    for word in text.split():\n",
    "        n_text[row['Interesting?']] +=1\n",
    "        total_words.add(word)\n",
    "        if word in count_words[row['Interesting?']].keys():\n",
    "            count_words[row['Interesting?']][word] += 1\n",
    "        else:\n",
    "            n_unique_text[row['Interesting?']] +=1\n",
    "            count_words[row['Interesting?']][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'yes': 34, 'no': 28})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_unique_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': {'oracle': 1,\n",
       "  'open': 1,\n",
       "  'sources': 1,\n",
       "  'java': 1,\n",
       "  'machine': 6,\n",
       "  'learning': 7,\n",
       "  'library': 1,\n",
       "  'auto': 1,\n",
       "  'ml': 1,\n",
       "  'bridging': 1,\n",
       "  'skill': 1,\n",
       "  'gaps': 1,\n",
       "  'with': 1,\n",
       "  'definining': 1,\n",
       "  'ai': 2,\n",
       "  'deep': 1,\n",
       "  'martech': 1,\n",
       "  'tool': 1,\n",
       "  'can': 1,\n",
       "  'help': 1,\n",
       "  'separate': 1,\n",
       "  'covid': 1,\n",
       "  'related': 1,\n",
       "  'claim': 1,\n",
       "  'dbs': 1,\n",
       "  'taking': 1,\n",
       "  'for': 1,\n",
       "  'spin': 1,\n",
       "  'deepmind': 1,\n",
       "  'introduce': 1,\n",
       "  'model': 1,\n",
       "  'improve': 1,\n",
       "  'google': 1,\n",
       "  'maps': 1},\n",
       " 'no': {'the': 2,\n",
       "  'reason': 1,\n",
       "  'trump': 2,\n",
       "  'not': 1,\n",
       "  'trying': 1,\n",
       "  'save': 1,\n",
       "  'economy': 3,\n",
       "  'it': 1,\n",
       "  'fed': 1,\n",
       "  'day': 1,\n",
       "  'time': 1,\n",
       "  'for': 1,\n",
       "  'to': 2,\n",
       "  'get': 1,\n",
       "  'tuneup': 1,\n",
       "  'donald': 1,\n",
       "  'chance': 1,\n",
       "  'peel': 1,\n",
       "  'off': 1,\n",
       "  'hispanic': 1,\n",
       "  'voters': 1,\n",
       "  'we': 1,\n",
       "  'must': 1,\n",
       "  'use': 1,\n",
       "  'covid': 1,\n",
       "  'crisis': 1,\n",
       "  'rehape': 1,\n",
       "  'society': 1}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 2,\n",
       " 'reason': 1,\n",
       " 'trump': 2,\n",
       " 'not': 1,\n",
       " 'trying': 1,\n",
       " 'save': 1,\n",
       " 'economy': 3,\n",
       " 'it': 1,\n",
       " 'fed': 1,\n",
       " 'day': 1,\n",
       " 'time': 1,\n",
       " 'for': 1,\n",
       " 'to': 2,\n",
       " 'get': 1,\n",
       " 'tuneup': 1,\n",
       " 'donald': 1,\n",
       " 'chance': 1,\n",
       " 'peel': 1,\n",
       " 'off': 1,\n",
       " 'hispanic': 1,\n",
       " 'voters': 1,\n",
       " 'we': 1,\n",
       " 'must': 1,\n",
       " 'use': 1,\n",
       " 'covid': 1,\n",
       " 'crisis': 1,\n",
       " 'rehape': 1,\n",
       " 'society': 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029411764705882353"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = dict(count_words)\n",
    "for class_i in count_words.keys():\n",
    "    for word in count_words[class_i]:\n",
    "        likelihoods[class_i][word] /= n_unique_text[class_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': {'oracle': 0.029411764705882353,\n",
       "  'open': 0.029411764705882353,\n",
       "  'sources': 0.029411764705882353,\n",
       "  'java': 0.029411764705882353,\n",
       "  'machine': 0.17647058823529413,\n",
       "  'learning': 0.20588235294117646,\n",
       "  'library': 0.029411764705882353,\n",
       "  'auto': 0.029411764705882353,\n",
       "  'ml': 0.029411764705882353,\n",
       "  'bridging': 0.029411764705882353,\n",
       "  'skill': 0.029411764705882353,\n",
       "  'gaps': 0.029411764705882353,\n",
       "  'with': 0.029411764705882353,\n",
       "  'definining': 0.029411764705882353,\n",
       "  'ai': 0.058823529411764705,\n",
       "  'deep': 0.029411764705882353,\n",
       "  'martech': 0.029411764705882353,\n",
       "  'tool': 0.029411764705882353,\n",
       "  'can': 0.029411764705882353,\n",
       "  'help': 0.029411764705882353,\n",
       "  'separate': 0.029411764705882353,\n",
       "  'covid': 0.029411764705882353,\n",
       "  'related': 0.029411764705882353,\n",
       "  'claim': 0.029411764705882353,\n",
       "  'dbs': 0.029411764705882353,\n",
       "  'taking': 0.029411764705882353,\n",
       "  'for': 0.029411764705882353,\n",
       "  'spin': 0.029411764705882353,\n",
       "  'deepmind': 0.029411764705882353,\n",
       "  'introduce': 0.029411764705882353,\n",
       "  'model': 0.029411764705882353,\n",
       "  'improve': 0.029411764705882353,\n",
       "  'google': 0.029411764705882353,\n",
       "  'maps': 0.029411764705882353},\n",
       " 'no': {'the': 0.07142857142857142,\n",
       "  'reason': 0.03571428571428571,\n",
       "  'trump': 0.07142857142857142,\n",
       "  'not': 0.03571428571428571,\n",
       "  'trying': 0.03571428571428571,\n",
       "  'save': 0.03571428571428571,\n",
       "  'economy': 0.10714285714285714,\n",
       "  'it': 0.03571428571428571,\n",
       "  'fed': 0.03571428571428571,\n",
       "  'day': 0.03571428571428571,\n",
       "  'time': 0.03571428571428571,\n",
       "  'for': 0.03571428571428571,\n",
       "  'to': 0.07142857142857142,\n",
       "  'get': 0.03571428571428571,\n",
       "  'tuneup': 0.03571428571428571,\n",
       "  'donald': 0.03571428571428571,\n",
       "  'chance': 0.03571428571428571,\n",
       "  'peel': 0.03571428571428571,\n",
       "  'off': 0.03571428571428571,\n",
       "  'hispanic': 0.03571428571428571,\n",
       "  'voters': 0.03571428571428571,\n",
       "  'we': 0.03571428571428571,\n",
       "  'must': 0.03571428571428571,\n",
       "  'use': 0.03571428571428571,\n",
       "  'covid': 0.03571428571428571,\n",
       "  'crisis': 0.03571428571428571,\n",
       "  'rehape': 0.03571428571428571,\n",
       "  'society': 0.03571428571428571}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing dengan laplace\n",
    "\n",
    "Karena ada kata yang tidak muncul maka untuk mengatasi *zero-probabilities* bisa diselesaikan dengan menggunakan smoothing. Menggunakan jumlah frequensi per kata, kita masih bisa mendapatkan probability dari $P(text|Interesting?)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = 'system target ai adoption challenge machine learning builder'\n",
    "split_text_1 = text_1.split()\n",
    "text_2 = 'trump destroying economy though'\n",
    "split_text_2 = text_2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system 0 1 34 60 94 0.010638297872340425\n",
      "target 0 1 34 60 94 0.010638297872340425\n",
      "ai 2 3 34 60 94 0.031914893617021274\n",
      "adoption 0 1 34 60 94 0.010638297872340425\n",
      "challenge 0 1 34 60 94 0.010638297872340425\n",
      "machine 6 7 34 60 94 0.07446808510638298\n",
      "learning 7 8 34 60 94 0.0851063829787234\n",
      "builder 0 1 34 60 94 0.010638297872340425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'system': 0.010638297872340425,\n",
       "             'target': 0.010638297872340425,\n",
       "             'ai': 0.031914893617021274,\n",
       "             'adoption': 0.010638297872340425,\n",
       "             'challenge': 0.010638297872340425,\n",
       "             'machine': 0.07446808510638298,\n",
       "             'learning': 0.0851063829787234,\n",
       "             'builder': 0.010638297872340425})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text1_y = defaultdict(float)\n",
    "for word in split_text_1:\n",
    "    if word in count_words['yes'].keys():\n",
    "        count = count_words['yes'][word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob=(count+1)/(n_unique_text['yes']+len(total_words))\n",
    "    print(word, count, count+1, n_unique_text['yes'], len(total_words), n_unique_text['yes']+len(total_words), prob)\n",
    "    prob_text1_y[word] = prob\n",
    "prob_text1_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system 0 1 28 60 88 0.011363636363636364\n",
      "target 0 1 28 60 88 0.011363636363636364\n",
      "ai 0 1 28 60 88 0.011363636363636364\n",
      "adoption 0 1 28 60 88 0.011363636363636364\n",
      "challenge 0 1 28 60 88 0.011363636363636364\n",
      "machine 0 1 28 60 88 0.011363636363636364\n",
      "learning 0 1 28 60 88 0.011363636363636364\n",
      "builder 0 1 28 60 88 0.011363636363636364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'system': 0.011363636363636364,\n",
       "             'target': 0.011363636363636364,\n",
       "             'ai': 0.011363636363636364,\n",
       "             'adoption': 0.011363636363636364,\n",
       "             'challenge': 0.011363636363636364,\n",
       "             'machine': 0.011363636363636364,\n",
       "             'learning': 0.011363636363636364,\n",
       "             'builder': 0.011363636363636364})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text1_n = defaultdict(float)\n",
    "for word in split_text_1:\n",
    "    if word in count_words['no'].keys():\n",
    "        count = count_words['no'][word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob=(count+1)/(n_unique_text['no']+len(total_words))\n",
    "    print(word, count, count+1, n_unique_text['no'], len(total_words), n_unique_text['no']+len(total_words), prob)\n",
    "    prob_text1_n[word] = prob\n",
    "prob_text1_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7560459429262354e-14"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text1_y_res = 1\n",
    "for prob_q in prob_text1_y.values():\n",
    "    prob_text1_y_res *= prob_q\n",
    "prob_text1_y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.780600668249926e-16"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text1_n_res = 1\n",
    "for prob_q in prob_text1_n.values():\n",
    "    prob_text1_n_res *= prob_q\n",
    "prob_text1_n_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "if ((prob_text1_y_res*prior_yes)>(prob_text1_n_res*prior_no)):\n",
    "    print('YES')\n",
    "else:\n",
    "    print('NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text kedua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump 0 1 34 60 94 0.010638297872340425\n",
      "destroying 0 1 34 60 94 0.010638297872340425\n",
      "economy 0 1 34 60 94 0.010638297872340425\n",
      "though 0 1 34 60 94 0.010638297872340425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'trump': 0.010638297872340425,\n",
       "             'destroying': 0.010638297872340425,\n",
       "             'economy': 0.010638297872340425,\n",
       "             'though': 0.010638297872340425})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text2_y = defaultdict(float)\n",
    "for word in split_text_2:\n",
    "    if word in count_words['yes'].keys():\n",
    "        count = count_words['yes'][word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob=(count+1)/(n_unique_text['yes']+len(total_words))\n",
    "    print(word, count, count+1, n_unique_text['yes'], len(total_words), n_unique_text['yes']+len(total_words), prob)\n",
    "    prob_text2_y[word] = prob\n",
    "prob_text2_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump 2 3 28 60 88 0.03409090909090909\n",
      "destroying 0 1 28 60 88 0.011363636363636364\n",
      "economy 3 4 28 60 88 0.045454545454545456\n",
      "though 0 1 28 60 88 0.011363636363636364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'trump': 0.03409090909090909,\n",
       "             'destroying': 0.011363636363636364,\n",
       "             'economy': 0.045454545454545456,\n",
       "             'though': 0.011363636363636364})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text2_n = defaultdict(float)\n",
    "for word in split_text_2:\n",
    "    if word in count_words['no'].keys():\n",
    "        count = count_words['no'][word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob=(count+1)/(n_unique_text['no']+len(total_words))\n",
    "    print(word, count, count+1, n_unique_text['no'], len(total_words), n_unique_text['no']+len(total_words), prob)\n",
    "    prob_text2_n[word] = prob\n",
    "prob_text2_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2808214307451655e-08"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text2_y_res = 1\n",
    "for prob_q in prob_text2_y.values():\n",
    "    prob_text2_y_res *= prob_q\n",
    "prob_text2_y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0010159825148556e-07"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_text2_n_res = 1\n",
    "for prob_q in prob_text2_n.values():\n",
    "    prob_text2_n_res *= prob_q\n",
    "prob_text2_n_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n"
     ]
    }
   ],
   "source": [
    "if ((prob_text2_y_res*prior_yes)>(prob_text2_n_res*prior_no)):\n",
    "    print('YES')\n",
    "else:\n",
    "    print('NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pakai sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ai</th>\n",
       "      <th>auto</th>\n",
       "      <th>bridging</th>\n",
       "      <th>can</th>\n",
       "      <th>claim</th>\n",
       "      <th>covid</th>\n",
       "      <th>dbs</th>\n",
       "      <th>deep</th>\n",
       "      <th>deepmind</th>\n",
       "      <th>definining</th>\n",
       "      <th>...</th>\n",
       "      <th>open</th>\n",
       "      <th>oracle</th>\n",
       "      <th>related</th>\n",
       "      <th>separate</th>\n",
       "      <th>skill</th>\n",
       "      <th>sources</th>\n",
       "      <th>spin</th>\n",
       "      <th>taking</th>\n",
       "      <th>tool</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ai  auto  bridging  can  claim  covid  dbs  deep  deepmind  definining  \\\n",
       "0   0     0         0    0      0      0    0     0         0           0   \n",
       "1   0     1         1    0      0      0    0     0         0           0   \n",
       "2   1     0         0    0      0      0    0     1         0           1   \n",
       "3   1     0         0    1      1      1    0     0         0           0   \n",
       "4   0     0         0    0      0      0    1     0         0           0   \n",
       "5   0     0         0    0      0      0    0     0         1           0   \n",
       "\n",
       "   ...  open  oracle  related  separate  skill  sources  spin  taking  tool  \\\n",
       "0  ...     1       1        0         0      0        1     0       0     0   \n",
       "1  ...     0       0        0         0      1        0     0       0     0   \n",
       "2  ...     0       0        0         0      0        0     0       0     0   \n",
       "3  ...     0       0        1         1      0        0     0       0     1   \n",
       "4  ...     0       0        0         0      0        0     1       1     0   \n",
       "5  ...     0       0        0         0      0        0     0       0     0   \n",
       "\n",
       "   with  \n",
       "0     0  \n",
       "1     1  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "5     0  \n",
       "\n",
       "[6 rows x 34 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "yes_docs = [row['Title of Article'] for i, row in data.iterrows() if row['Interesting?'] == 'yes']\n",
    "\n",
    "vec_y = CountVectorizer()\n",
    "X_y = vec_y.fit_transform(yes_docs)\n",
    "tdm_y = pd.DataFrame(X_y.toarray(), columns=vec_y.get_feature_names())\n",
    "\n",
    "tdm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chance</th>\n",
       "      <th>covid</th>\n",
       "      <th>crisis</th>\n",
       "      <th>day</th>\n",
       "      <th>donald</th>\n",
       "      <th>economy</th>\n",
       "      <th>fed</th>\n",
       "      <th>for</th>\n",
       "      <th>get</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>society</th>\n",
       "      <th>the</th>\n",
       "      <th>time</th>\n",
       "      <th>to</th>\n",
       "      <th>trump</th>\n",
       "      <th>trying</th>\n",
       "      <th>tuneup</th>\n",
       "      <th>use</th>\n",
       "      <th>voters</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chance  covid  crisis  day  donald  economy  fed  for  get  hispanic  ...  \\\n",
       "0       0      0       0    0       0        1    0    0    0         0  ...   \n",
       "1       0      0       0    1       0        1    1    1    1         0  ...   \n",
       "2       1      0       0    0       1        0    0    0    0         1  ...   \n",
       "3       0      1       1    0       0        1    0    0    0         0  ...   \n",
       "\n",
       "   society  the  time  to  trump  trying  tuneup  use  voters  we  \n",
       "0        0    1     0   0      1       1       0    0       0   0  \n",
       "1        0    1     1   1      0       0       1    0       0   0  \n",
       "2        0    0     0   1      1       0       0    0       1   0  \n",
       "3        1    0     0   0      0       0       0    1       0   1  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_docs = [row['Title of Article'] for i, row in data.iterrows() if row['Interesting?'] == 'no']\n",
    "\n",
    "vec_n = CountVectorizer()\n",
    "X_n = vec_n.fit_transform(no_docs)\n",
    "tdm_n = pd.DataFrame(X_n.toarray(), columns=vec_n.get_feature_names())\n",
    "\n",
    "tdm_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai': 2,\n",
       " 'auto': 1,\n",
       " 'bridging': 1,\n",
       " 'can': 1,\n",
       " 'claim': 1,\n",
       " 'covid': 1,\n",
       " 'dbs': 1,\n",
       " 'deep': 1,\n",
       " 'deepmind': 1,\n",
       " 'definining': 1,\n",
       " 'for': 1,\n",
       " 'gaps': 1,\n",
       " 'google': 1,\n",
       " 'help': 1,\n",
       " 'improve': 1,\n",
       " 'introduce': 1,\n",
       " 'java': 1,\n",
       " 'learning': 7,\n",
       " 'library': 1,\n",
       " 'machine': 6,\n",
       " 'maps': 1,\n",
       " 'martech': 1,\n",
       " 'ml': 1,\n",
       " 'model': 1,\n",
       " 'open': 1,\n",
       " 'oracle': 1,\n",
       " 'related': 1,\n",
       " 'separate': 1,\n",
       " 'skill': 1,\n",
       " 'sources': 1,\n",
       " 'spin': 1,\n",
       " 'taking': 1,\n",
       " 'tool': 1,\n",
       " 'with': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_y = vec_y.get_feature_names()\n",
    "count_list_y = X_y.toarray().sum(axis=0)\n",
    "freq_y = dict(zip(word_list_y, count_list_y))\n",
    "freq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_list_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c68e02343725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_list_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'count_list_n' is not defined"
     ]
    }
   ],
   "source": [
    "len(count_list_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chance': 1,\n",
       " 'covid': 1,\n",
       " 'crisis': 1,\n",
       " 'day': 1,\n",
       " 'donald': 1,\n",
       " 'economy': 3,\n",
       " 'fed': 1,\n",
       " 'for': 1,\n",
       " 'get': 1,\n",
       " 'hispanic': 1,\n",
       " 'it': 1,\n",
       " 'must': 1,\n",
       " 'not': 1,\n",
       " 'off': 1,\n",
       " 'peel': 1,\n",
       " 'reason': 1,\n",
       " 'rehape': 1,\n",
       " 'save': 1,\n",
       " 'society': 1,\n",
       " 'the': 2,\n",
       " 'time': 1,\n",
       " 'to': 2,\n",
       " 'trump': 2,\n",
       " 'trying': 1,\n",
       " 'tuneup': 1,\n",
       " 'use': 1,\n",
       " 'voters': 1,\n",
       " 'we': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_n = vec_n.get_feature_names()\n",
    "count_list_n = X_n.toarray().sum(axis=0)\n",
    "freq_n = dict(zip(word_list_n, count_list_n))\n",
    "freq_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai': 0.058823529411764705,\n",
       " 'auto': 0.029411764705882353,\n",
       " 'bridging': 0.029411764705882353,\n",
       " 'can': 0.029411764705882353,\n",
       " 'claim': 0.029411764705882353,\n",
       " 'covid': 0.029411764705882353,\n",
       " 'dbs': 0.029411764705882353,\n",
       " 'deep': 0.029411764705882353,\n",
       " 'deepmind': 0.029411764705882353,\n",
       " 'definining': 0.029411764705882353,\n",
       " 'for': 0.029411764705882353,\n",
       " 'gaps': 0.029411764705882353,\n",
       " 'google': 0.029411764705882353,\n",
       " 'help': 0.029411764705882353,\n",
       " 'improve': 0.029411764705882353,\n",
       " 'introduce': 0.029411764705882353,\n",
       " 'java': 0.029411764705882353,\n",
       " 'learning': 0.20588235294117646,\n",
       " 'library': 0.029411764705882353,\n",
       " 'machine': 0.17647058823529413,\n",
       " 'maps': 0.029411764705882353,\n",
       " 'martech': 0.029411764705882353,\n",
       " 'ml': 0.029411764705882353,\n",
       " 'model': 0.029411764705882353,\n",
       " 'open': 0.029411764705882353,\n",
       " 'oracle': 0.029411764705882353,\n",
       " 'related': 0.029411764705882353,\n",
       " 'separate': 0.029411764705882353,\n",
       " 'skill': 0.029411764705882353,\n",
       " 'sources': 0.029411764705882353,\n",
       " 'spin': 0.029411764705882353,\n",
       " 'taking': 0.029411764705882353,\n",
       " 'tool': 0.029411764705882353,\n",
       " 'with': 0.029411764705882353}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_y = []\n",
    "for word, count in zip(word_list_y, count_list_y):\n",
    "    prob_y.append(count/len(word_list_y))\n",
    "dict(zip(word_list_y, prob_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chance': 0.03571428571428571,\n",
       " 'covid': 0.03571428571428571,\n",
       " 'crisis': 0.03571428571428571,\n",
       " 'day': 0.03571428571428571,\n",
       " 'donald': 0.03571428571428571,\n",
       " 'economy': 0.10714285714285714,\n",
       " 'fed': 0.03571428571428571,\n",
       " 'for': 0.03571428571428571,\n",
       " 'get': 0.03571428571428571,\n",
       " 'hispanic': 0.03571428571428571,\n",
       " 'it': 0.03571428571428571,\n",
       " 'must': 0.03571428571428571,\n",
       " 'not': 0.03571428571428571,\n",
       " 'off': 0.03571428571428571,\n",
       " 'peel': 0.03571428571428571,\n",
       " 'reason': 0.03571428571428571,\n",
       " 'rehape': 0.03571428571428571,\n",
       " 'save': 0.03571428571428571,\n",
       " 'society': 0.03571428571428571,\n",
       " 'the': 0.07142857142857142,\n",
       " 'time': 0.03571428571428571,\n",
       " 'to': 0.07142857142857142,\n",
       " 'trump': 0.07142857142857142,\n",
       " 'trying': 0.03571428571428571,\n",
       " 'tuneup': 0.03571428571428571,\n",
       " 'use': 0.03571428571428571,\n",
       " 'voters': 0.03571428571428571,\n",
       " 'we': 0.03571428571428571}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_n = []\n",
    "for word, count in zip(word_list_n, count_list_n):\n",
    "    prob_n.append(count/len(word_list_n))\n",
    "dict(zip(word_list_n, prob_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [row['Title of Article'] for i, row in data.iterrows()]\n",
    "\n",
    "vec = CountVectorizer(binary=True)\n",
    "X_all = vec.fit_transform(articles)\n",
    "total_features = len(vec.get_feature_names())\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count_features_y = count_list_y.sum(axis=0)\n",
    "total_count_features_n = count_list_n.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_features_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_features_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system 0 1 46 60 106\n",
      "target 0 1 46 60 106\n",
      "ai 2 3 46 60 106\n",
      "adoption 0 1 46 60 106\n",
      "challenge 0 1 46 60 106\n",
      "machine 6 7 46 60 106\n",
      "learning 7 8 46 60 106\n",
      "builder 0 1 46 60 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'system': 0.009433962264150943,\n",
       " 'target': 0.009433962264150943,\n",
       " 'ai': 0.02830188679245283,\n",
       " 'adoption': 0.009433962264150943,\n",
       " 'challenge': 0.009433962264150943,\n",
       " 'machine': 0.0660377358490566,\n",
       " 'learning': 0.07547169811320754,\n",
       " 'builder': 0.009433962264150943}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_y_no1 = []\n",
    "for word in split_text_1:\n",
    "    if word in freq_y.keys():\n",
    "        count = freq_y[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    print(word, count, count+1, total_count_features_y, total_features, total_count_features_y+total_features)\n",
    "    prob_y_no1.append((count+1)/(total_count_features_y+total_features))\n",
    "dict(zip(split_text_1, prob_y_no1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system 0 1 33 60 106\n",
      "target 0 1 33 60 106\n",
      "ai 0 1 33 60 106\n",
      "adoption 0 1 33 60 106\n",
      "challenge 0 1 33 60 106\n",
      "machine 0 1 33 60 106\n",
      "learning 0 1 33 60 106\n",
      "builder 0 1 33 60 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'system': 0.010752688172043012,\n",
       " 'target': 0.010752688172043012,\n",
       " 'ai': 0.010752688172043012,\n",
       " 'adoption': 0.010752688172043012,\n",
       " 'challenge': 0.010752688172043012,\n",
       " 'machine': 0.010752688172043012,\n",
       " 'learning': 0.010752688172043012,\n",
       " 'builder': 0.010752688172043012}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_n_no1 = []\n",
    "for word in split_text_1:\n",
    "    if word in freq_n.keys():\n",
    "        count = freq_n[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    print(word, count, count+1, total_count_features_n, total_features, total_count_features_y+total_features)\n",
    "    prob_n_no1.append((count+1)/(total_count_features_n+total_features))\n",
    "dict(zip(split_text_1, prob_n_no1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump 0 1 46 60 106\n",
      "destroying 0 1 46 60 106\n",
      "economy 0 1 46 60 106\n",
      "though 0 1 46 60 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trump': 0.009433962264150943,\n",
       " 'destroying': 0.009433962264150943,\n",
       " 'economy': 0.009433962264150943,\n",
       " 'though': 0.009433962264150943}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_y_no2 = []\n",
    "for word in split_text_2:\n",
    "    if word in freq_y.keys():\n",
    "        count = freq_y[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    print(word, count, count+1, total_count_features_y, total_features, total_count_features_y+total_features)\n",
    "    prob_y_no2.append((count+1)/(total_count_features_y+total_features))\n",
    "dict(zip(split_text_2, prob_y_no2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump 2 3 33 60 106\n",
      "destroying 0 1 33 60 106\n",
      "economy 3 4 33 60 106\n",
      "though 0 1 33 60 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trump': 0.03225806451612903,\n",
       " 'destroying': 0.010752688172043012,\n",
       " 'economy': 0.043010752688172046,\n",
       " 'though': 0.010752688172043012}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_n_no2 = []\n",
    "for word in split_text_2:\n",
    "    if word in freq_n.keys():\n",
    "        count = freq_n[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    print(word, count, count+1, total_count_features_n, total_features, total_count_features_y+total_features)\n",
    "    prob_n_no2.append((count+1)/(total_count_features_n+total_features))\n",
    "dict(zip(split_text_2, prob_n_no2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_no1_total = np.prod(prob_n_no1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7870487973842298e-16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_y_no1_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(prob_n_no1)>np.prod(prob_y_no1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(prob_n_no2)>np.prod(prob_y_no2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('compvis': conda)",
   "language": "python",
   "name": "python37664bitcompvisconda2d3448796e3e49d498304dbbfe353f71"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
